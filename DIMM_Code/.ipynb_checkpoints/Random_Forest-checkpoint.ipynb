{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "193f92ef-1655-4c5e-a023-d977839d871a",
   "metadata": {},
   "source": [
    "# Dataframe Prep, Random Forest Modeling and Evaluation\n",
    "\n",
    "-This notebook reads in the df_gen, df_slope, and df_ruby notebooks from Processing\n",
    "\n",
    "-The filtering gets a little complicated here, heavy annotations for clarity. I'm creating both a RF for progeny (first here), then mothers. \n",
    "\n",
    "-Output should be shap files, accuracy predicitions, and pred vs actual correlation plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0df244-8ea2-483c-9b73-8cd709fa469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "import shap\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# makes figures look better in Jupyter\n",
    "sns.set_context('talk')\n",
    "sns.set_style(\"ticks\")\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7728a2a2-1bd1-466f-9498-64fa7433334b",
   "metadata": {},
   "source": [
    "## Filtering and Merging Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3555b872-6028-4e85-abb6-b05de76966f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_output = ''\n",
    "df_gen = pd.read_csv(os.path.join(plot_output, 'CellCycle_Stats.csv'))\n",
    "df_slope = pd.read_csv(os.path.join(plot_output, 'Switch_Stats.csv'))\n",
    "df_ruby = pd.read_csv(os.path.join(plot_output, 'mRuby_Stats.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5bbbfa-f34b-4870-bf24-fa2c66134f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering incomplete cycles\n",
    "df_gen_no_end_cycle = df_gen[df_gen['end_time']!=1080] #removes incomplete cycles at the end of the expt\n",
    "\n",
    "#Now remove cycles where cells fall out end of channel - defined as cycles that both don't have a following cycle and don't have valid cell IDs through the last time point\n",
    "df_gen_no_end_cycle = df_gen_no_end_cycle.sort_values(by=['unique_ID', 'cell_id', 'cycle']) #sort\n",
    "df_gen_no_end_cycle['next_cycle'] = df_gen_no_end_cycle.groupby(['unique_ID','cell_id'])['cycle'].shift(-1) #find following cycle\n",
    "df_gen_no_lost_cells = df_gen_no_end_cycle[(df_gen_no_end_cycle['next_cycle'] == df_gen_no_end_cycle['cycle'] + 1) | (df_gen_no_end_cycle['last_valid_cell_time'] == 1080)].copy() #filter\n",
    "\n",
    "#Remove first cycle as that's also incomplete\n",
    "df_gen_filtered = df_gen_no_lost_cells[df_gen_no_lost_cells['start_time']!=0]\n",
    "\n",
    "print(len(df_gen))\n",
    "print(len(df_gen_no_end_cycle))\n",
    "print(len(df_gen_no_lost_cells))\n",
    "print(len(df_gen_filtered))\n",
    "columns_with_nan = df_gen_filtered.isna().sum()\n",
    "columns_with_nan = columns_with_nan[columns_with_nan > 0]\n",
    "print(columns_with_nan)\n",
    "#rows_with_nan = df_gen_filtered[df_gen_filtered.isnull().any(axis=1)]\n",
    "#print(rows_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e64227-4d74-4602-9597-fe2e5e1d7db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging into all stats dataframe\n",
    "gen_slope = df_gen_filtered.merge(df_slope, on=['unique_ID', 'cell_id'], how='left', suffixes=('_gen','_slope'))\n",
    "all_stats = gen_slope.merge(df_ruby, on=['unique_ID', 'cell_id'], how='left', suffixes=('_genslope','_ruby'))\n",
    "all_stats = all_stats[all_stats['category'] == 'switch']\n",
    "#Adding a boolean for if the cycle is the one where the response happens\n",
    "all_stats['response_cycle'] = (all_stats['start_time']<=all_stats['start_inc']) & (all_stats['start_inc']<all_stats['end_time'])\n",
    "all_stats['start_inc'] = all_stats['start_inc'].astype(float)\n",
    "all_stats['end_inc'] = all_stats['end_inc'].astype(float)\n",
    "all_stats['gfp_on'] = all_stats['gfp_on'].astype(float)\n",
    "all_stats.to_csv(plot_output +'all_stats_20250627.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5526358-2e35-4e62-bbcf-530ea49de616",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_gen_filtered))\n",
    "print(len(gen_slope))\n",
    "print(len(all_stats))\n",
    "all_stats.columns\n",
    "columns_with_nan = all_stats.isna().sum()\n",
    "columns_with_nan = columns_with_nan[columns_with_nan > 0]\n",
    "print(columns_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3500a029-2d18-447b-bd46-7dc2d5cf2ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking up the first cycle duration and appending to the table (note this has to be found on the unfiltered df_gen)\n",
    "#Getting the duration of that first cycle (ie where in cell cycle was the og mother before the transition)\n",
    "#should be one value per unique ID\n",
    "first_cycle_lookup = (\n",
    "    df_gen[(df_gen['parent'] == 0) & (df_gen['cycle'] == 0)] # ensure only one per unique_ID\n",
    "    .set_index('unique_ID')['cycle_duration']\n",
    ")\n",
    "\n",
    "all_stats['initial_cycle_duration'] = all_stats['unique_ID'].map(first_cycle_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9fc289-c922-480a-a831-d899b93d3aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into mothers and daughters dfs\n",
    "all_stats_mothers = all_stats[all_stats['cell_id']==1]\n",
    "all_stats_prog = all_stats[all_stats['cell_id']!=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd4f889-e2f1-44c2-b07c-8800d6a7a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retain only needed columns for mothers\n",
    "cols_to_keep_mothers = ['unique_ID', 'channel_width', 'experiment_gen', 'cell_id', 'cycle', \n",
    "                'category', 'cycle_duration', 'start_length', 'mean_ruby_lifetime', \n",
    "                'initial_cycle_duration', 'time_of_min_slope_ruby', 'max_ruby', \n",
    "                'max_ruby_time', 'end_length', 'avg_elong_rate', 'total_growth', \n",
    "                'start_inc', 'min_slope_ruby', 'response_cycle']\n",
    "all_stats_mothers_rc = all_stats_mothers[cols_to_keep_mothers]\n",
    "all_stats_mothers_rc\n",
    "columns_with_nan = all_stats_mothers_rc.isna().sum()\n",
    "columns_with_nan = columns_with_nan[columns_with_nan > 0]\n",
    "print(columns_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bebbd1-4cf9-4e7c-8fbd-57fa876d6009",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep_prog = ['unique_ID', 'channel_width', 'experiment_gen', 'cell_id', 'cycle', \n",
    "                'category', 'cycle_duration', 'start_length', 'mean_ruby_lifetime', \n",
    "                'initial_cycle_duration', 'time_of_min_slope_ruby', 'max_ruby', \n",
    "                'max_ruby_time', 'end_length', 'avg_elong_rate', 'total_growth', \n",
    "                'start_inc', 'parent_start_inc', 'y_pos_start_inc', 'y_pos_appearance', \n",
    "               'min_slope_ruby', 'response_cycle']\n",
    "all_stats_prog_rc = all_stats_prog[cols_to_keep_prog]\n",
    "all_stats_prog_rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3212530d-2fde-41ff-97a0-18e3cd2c69ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get numbers out of arrays in case any weirdness happened with merges\n",
    "def unwrap_scalar_array(x):\n",
    "    if isinstance(x, np.ndarray) and x.size == 1:\n",
    "        return x.item()\n",
    "    return x\n",
    "for column in all_stats_mothers_rc:\n",
    "    all_stats_mothers_rc[column] = all_stats_mothers_rc[column].apply(unwrap_scalar_array)\n",
    "for column in all_stats_prog_rc:\n",
    "    all_stats_prog_rc[column] = all_stats_prog_rc[column].apply(unwrap_scalar_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad21bdd-3ccc-44f3-9b63-8b530f5943f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now find variables that are on a per cycle basis and get the averages of them, retain ones that are the same for every cycle\n",
    "#should have 1 row per cell now\n",
    "for col in all_stats_mothers_rc.columns:\n",
    "    unhashable = all_stats_mothers_rc[col].apply(lambda x: isinstance(x, (list, np.ndarray))).any()\n",
    "    if unhashable:\n",
    "        print(f\"Column '{col}' contains unhashable types like list or ndarray.\")\n",
    "\n",
    "grouped = all_stats_mothers_rc.groupby(['unique_ID', 'cell_id'])\n",
    "\n",
    "# Identify constant variables (same value across all cycles in each group)\n",
    "constant_vars = []\n",
    "for col in all_stats_mothers_rc.columns:\n",
    "    if col not in ['unique_ID', 'cell_id', 'cycle']:\n",
    "        nunique_per_group = grouped[col].nunique()\n",
    "        if nunique_per_group.max() == 1:\n",
    "            constant_vars.append(col)\n",
    "print(\"constant variables, keeping one:\",constant_vars)\n",
    "\n",
    "# Identify varying variables (change across cycles)\n",
    "varying_vars = [col for col in all_stats_mothers_rc.columns\n",
    "                if col not in ['unique_ID', 'cell_id', 'cycle']\n",
    "                and col not in constant_vars]\n",
    "print(\"cycle based variables, averaging:\",varying_vars)\n",
    "\n",
    "# Aggregate\n",
    "constant_df = grouped[constant_vars].first().reset_index()\n",
    "varying_df = grouped[varying_vars].mean().reset_index()\n",
    "\n",
    "# Rename varying columns\n",
    "varying_df = varying_df.rename(columns={col: f\"{col}_avg\" for col in varying_vars})\n",
    "\n",
    "# Merge\n",
    "avg_stats_mothers = pd.merge(constant_df, varying_df, on=['unique_ID', 'cell_id'])\n",
    "avg_stats_mothers = avg_stats_mothers.drop('response_cycle_avg', axis=1)\n",
    "columns_with_nan = avg_stats_mothers.isna().sum()\n",
    "columns_with_nan = columns_with_nan[columns_with_nan > 0]\n",
    "print(columns_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ee56af-07ad-475b-b748-6f392c47c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now find variables that are on a per cycle basis and get the averages of them, retain ones that are the same for every cycle\n",
    "#should have 1 row per cell now\n",
    "for col in all_stats_prog_rc.columns:\n",
    "    unhashable = all_stats_prog_rc[col].apply(lambda x: isinstance(x, (list, np.ndarray))).any()\n",
    "    if unhashable:\n",
    "        print(f\"Column '{col}' contains unhashable types like list or ndarray.\")\n",
    "\n",
    "grouped = all_stats_prog_rc.groupby(['unique_ID', 'cell_id'])\n",
    "\n",
    "# Identify constant variables (same value across all cycles in each group)\n",
    "constant_vars = []\n",
    "for col in all_stats_prog_rc.columns:\n",
    "    if col not in ['unique_ID', 'cell_id', 'cycle']:\n",
    "        nunique_per_group = grouped[col].nunique()\n",
    "        if nunique_per_group.max() == 1:\n",
    "            constant_vars.append(col)\n",
    "print(\"constant variables, keeping one:\",constant_vars)\n",
    "\n",
    "# Identify varying variables (change across cycles)\n",
    "varying_vars = [col for col in all_stats_prog_rc.columns\n",
    "                if col not in ['unique_ID', 'cell_id', 'cycle']\n",
    "                and col not in constant_vars]\n",
    "print(\"cycle based variables, averaging:\",varying_vars)\n",
    "\n",
    "# Aggregate\n",
    "constant_df = grouped[constant_vars].first().reset_index()\n",
    "varying_df = grouped[varying_vars].mean().reset_index()\n",
    "\n",
    "# Rename varying columns\n",
    "varying_df = varying_df.rename(columns={col: f\"{col}_avg\" for col in varying_vars})\n",
    "\n",
    "# Merge\n",
    "avg_stats_prog = pd.merge(constant_df, varying_df, on=['unique_ID', 'cell_id'])\n",
    "avg_stats_prog = avg_stats_prog.drop('response_cycle_avg', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf5e42e-3a4b-4664-a8a9-3e789b899846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now go back and get the response cycle only in a dataframe, then merge onto the averages. \n",
    "#we lose cells here that respond in the first or last incomplete cycles because they've already been filtered out of df_gen\n",
    "res_cycle_mothers_df = all_stats_mothers[all_stats_mothers['response_cycle']==True]\n",
    "\n",
    "\n",
    "res_cycle_prog_df = all_stats_prog[all_stats_prog['response_cycle']==True]\n",
    "for column in res_cycle_mothers_df:\n",
    "    res_cycle_mothers_df[column] = res_cycle_mothers_df[column].apply(unwrap_scalar_array)\n",
    "for column in res_cycle_prog_df:\n",
    "    res_cycle_prog_df[column] = res_cycle_prog_df[column].apply(unwrap_scalar_array)\n",
    "\n",
    "\n",
    "##For this merge we're merging onto the res_cycle_df because it has fewer cells \n",
    "final_forest_df_mothers = pd.merge( res_cycle_mothers_df, avg_stats_mothers, on = ['cell_id', 'unique_ID'],  how='left')\n",
    "print(len(final_forest_df_mothers))\n",
    "final_forest_df_prog = pd.merge(res_cycle_prog_df, avg_stats_prog, on = ['cell_id', 'unique_ID'],  how='left')\n",
    "print(len(final_forest_df_prog))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bebd96-f29d-4f72-b357-7b3721d17c39",
   "metadata": {},
   "source": [
    "## Random Forest Regressor and Evaluation - Mother Cells\n",
    "Steps:\n",
    "\n",
    "1. Define train and test data\n",
    "\n",
    "2. Remove any extraneous columns\n",
    "\n",
    "3. Define input and output columns\n",
    "\n",
    "4. Random Forest Regressor\n",
    "\n",
    "5. SHAP values and prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a80e8d2-cab0-40ce-8add-f7c68a62bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = ['unique_ID', 'channel_width_x', 'experiment_gen_x',\n",
    "        'mean_ruby_lifetime_x', 'initial_cycle_duration_x',\n",
    "        'max_ruby_x',  'max_ruby_time_x', \n",
    "       'start_inc_x', 'time_of_min_slope_ruby_x',\n",
    "       'cycle_duration_avg', 'start_length_avg', 'end_length_avg',\n",
    "       'avg_elong_rate_avg', 'total_growth_avg', \n",
    "        'cycle', 'cycle_duration', 'start_length',\n",
    "       'end_length', 'avg_elong_rate', 'total_growth', \n",
    "       ]\n",
    "final_forest_df_clean_mothers = final_forest_df_mothers[cols_to_keep]\n",
    "#There should be no NaNs at this point, if there are you need to drop the cell or lose the parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ccddc7-bd9f-4752-ae7e-ebcda287392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=train_test_split(final_forest_df_clean_mothers, test_size=0.3, random_state=0)\n",
    "train = train.drop(['unique_ID'], axis=1)\n",
    "test = test.drop(['unique_ID'], axis=1)\n",
    "#train = train.drop(['cell_id'], axis=1)\n",
    "#test = test.drop(['cell_id'], axis=1)\n",
    "train = train.drop(['cycle'], axis=1)\n",
    "test = test.drop(['cycle'], axis=1)\n",
    "\n",
    "# Create X_train,Y_train,X_test\n",
    "X_train = train.drop(['start_inc_x'], axis=1)\n",
    "Y_train = train['start_inc_x']\n",
    "\n",
    "X_test  = test.drop(['start_inc_x'], axis=1)\n",
    "Y_test  = test['start_inc_x']\n",
    "print(len(X_train))\n",
    "print(len(X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e60b29-7d68-4902-a4c7-f332a2037a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "random_forest = RandomForestRegressor(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "random_forest_preds = random_forest.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Example metrics\n",
    "print(\"Mean Squared Error:\", mean_squared_error(Y_test, random_forest_preds))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(Y_test, random_forest_preds))\n",
    "print(\"R^2 Score:\", r2_score(Y_test, random_forest_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba61d6c-085c-47e7-b721-acf946094680",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(random_forest)\n",
    "shap_values = explainer(X_test)\n",
    "n_features = X_test.shape[1]\n",
    "cmap = plt.colormaps[\"viridis\"].resampled(n_features)\n",
    "color_list = [cmap(i) for i in range(n_features)]\n",
    "shap.summary_plot(shap_values, X_test, cmap='viridis', show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c37912-cbaf-4a7e-99cc-caf8f8329a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.heatmap(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf17ef2-ddea-4677-a703-00bd4f9839bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=Y_test, y=random_forest_preds, s=50, edgecolor=\"white\")\n",
    "z = np.polyfit(Y_test, random_forest_preds, 1)  # Linear trendline (degree 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(Y_test, p(Y_test), \"lightsteelblue\")\n",
    "x = np.array([100, 850])\n",
    "y = 1 * x + 0\n",
    "plt.plot(x, y, \"black\")\n",
    "\n",
    "# Set the x and y axis limits to make the line visible\n",
    "plt.xlim(-6, 6)\n",
    "plt.ylim(-6, 6)\n",
    "plt.ylim(100, 850)\n",
    "plt.xlim(100,850)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d41384a-f634-4f1a-9a92-7e0b5b7649be",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df_mothers = pd.DataFrame({'Experimental': Y_test, 'Predicted': random_forest_preds})\n",
    "accuracy_df_mothers['individual_acc']= abs((accuracy_df_mothers['Predicted']-accuracy_df_mothers['Experimental'])/accuracy_df_mothers['Experimental'])\n",
    "accuracy = 1-(1/len(accuracy_df_mothers) * accuracy_df_mothers['individual_acc'].sum()) \n",
    "print(accuracy_df_mothers['individual_acc'].mean())\n",
    "print(accuracy_df_mothers['individual_acc'].std())\n",
    "print(accuracy)\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9522ec-f1b3-49dc-b65d-03f00ee5f578",
   "metadata": {},
   "source": [
    "## Random Forest and Evaluation - Progeny\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed34009-e0ad-4e50-b45c-868259c91ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = ['unique_ID', 'channel_width_x', 'experiment_gen_x',\n",
    "        'mean_ruby_lifetime_x', 'initial_cycle_duration_x',\n",
    "        'max_ruby_x',  \n",
    "       'start_inc_x',  \n",
    "       'cycle_duration_avg', 'start_length_avg', 'end_length_avg',\n",
    "       'avg_elong_rate_avg', 'total_growth_avg', \n",
    "        'cycle', 'cycle_duration', 'start_length',\n",
    "       'end_length', 'avg_elong_rate', 'total_growth', \n",
    "       ]\n",
    "final_forest_df_clean_prog = final_forest_df_prog[cols_to_keep]\n",
    "final_forest_df_clean_prog = final_forest_df_clean_prog.dropna() \n",
    "final_forest_df_clean_prog.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a742c4e-da35-4d9c-9ac2-6d0f6369efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=train_test_split(final_forest_df_clean_prog, test_size=0.3, random_state=0)\n",
    "train = train.drop(['unique_ID'], axis=1)\n",
    "test = test.drop(['unique_ID'], axis=1)\n",
    "#train = train.drop(['cell_id'], axis=1)\n",
    "#test = test.drop(['cell_id'], axis=1)\n",
    "train = train.drop(['cycle'], axis=1)\n",
    "test = test.drop(['cycle'], axis=1)\n",
    "\n",
    "# Create X_train,Y_train,X_test\n",
    "X_train = train.drop(['start_inc_x'], axis=1)\n",
    "Y_train = train['start_inc_x']\n",
    "\n",
    "X_test  = test.drop(['start_inc_x'], axis=1)\n",
    "Y_test  = test['start_inc_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668351da-b3cd-4068-906f-d415330a6a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "random_forest = RandomForestRegressor(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "random_forest_preds = random_forest.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Example metrics\n",
    "print(\"Mean Squared Error:\", mean_squared_error(Y_test, random_forest_preds))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(Y_test, random_forest_preds))\n",
    "print(\"R^2 Score:\", r2_score(Y_test, random_forest_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2000b05b-34d4-4586-81ad-c3ac14daad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(random_forest)\n",
    "shap_values = explainer(X_test)\n",
    "n_features = X_test.shape[1]\n",
    "cmap = plt.colormaps[\"viridis\"].resampled(n_features)\n",
    "color_list = [cmap(i) for i in range(n_features)]\n",
    "shap.summary_plot(shap_values, X_test, cmap='viridis', show=False)\n",
    "plt.savefig(plot_output +'/progeny_shap_plot.pdf',bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8767ac7-68a1-4224-af83-e6546a1341f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.heatmap(shap_values)\n",
    "plt.savefig(plot_output +'/progeny_shap_heatmap.pdf',bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43766a44-4044-41ae-8fe8-fcde5f6a0524",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=Y_test, y=random_forest_preds, s=50, color = \"#431c54\", edgecolor=\"white\")\n",
    "z = np.polyfit(Y_test, random_forest_preds, 1)  # Linear trendline (degree 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(Y_test, p(Y_test), \"#431c54\")\n",
    "x = np.array([100, 850])\n",
    "y = 1 * x + 0\n",
    "plt.plot(x, y, \"lightgrey\")\n",
    "\n",
    "# Set the x and y axis limits to make the line visible\n",
    "plt.xlim(-6, 6)\n",
    "plt.ylim(-6, 6)\n",
    "plt.ylim(100, 850)\n",
    "plt.xlim(100,850)\n",
    "plt.savefig(plot_output +'/progeny_expvspred.pdf',bbox_inches='tight', transparent=True)\n",
    "#len(random_forest_preds)\n",
    "len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b6c975-f969-4bd3-96ea-fe71180862f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df_prog = pd.DataFrame({'Experimental': Y_test, 'Predicted': random_forest_preds})\n",
    "accuracy_df_prog['individual_acc']= abs((accuracy_df_prog['Predicted']-accuracy_df_prog['Experimental'])/accuracy_df_prog['Experimental'])\n",
    "accuracy = 1-(1/len(accuracy_df_prog) * accuracy_df_prog['individual_acc'].sum()) \n",
    "print(accuracy_df_prog['individual_acc'].mean())\n",
    "print(accuracy_df_prog['individual_acc'].std())\n",
    "print(accuracy)\n",
    "accuracy_df_prog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982247c-7a75-491e-87ed-89ee7759fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(accuracy_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gmm",
   "language": "python",
   "name": "delta_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
